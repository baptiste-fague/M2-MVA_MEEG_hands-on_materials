{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dee22b1-4ccd-4a0a-846d-06bcdddae81c",
   "metadata": {},
   "source": [
    "# M/EEG exam instructions\n",
    "- Assignment format: \n",
    "    - mandatory: a notebook with your answers \n",
    "    - optional: an additional document with your answers to the conceptual questions\n",
    "- Please send your assignment to M.Corsi's email address\n",
    "- Deadline: \n",
    "    - **Feb 12th, 8AM.** Please not that an **extension will not be proposed.**"
   ]
  },
  {
   "cell_type": "code",
   "id": "0af3406f-1d6f-43d2-a6e0-2dfdf0b1b46b",
   "metadata": {},
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.stats import permutation_cluster_1samp_test as pcluster_test\n",
    "from mne.time_frequency import tfr_multitaper"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0765cb29-56ce-4c5e-8533-4b27e3301938",
   "metadata": {
    "tags": []
   },
   "source": "## Part 1 - Connectivity and Networks"
  },
  {
   "cell_type": "markdown",
   "id": "be41298e-d10e-4a4b-830b-808eb4e3a74e",
   "metadata": {},
   "source": [
    "Here is an EEG dataset to load:"
   ]
  },
  {
   "cell_type": "code",
   "id": "61d2193e-97a8-4161-8896-9f08b31944b5",
   "metadata": {},
   "source": [
    "#Define the parameters\n",
    "subject = 1  # use data from subject 1\n",
    "runs = [6, 10, 14]  # Motor imagery: hands vs feet\n",
    "\n",
    "# Extract raw data\n",
    "fnames = eegbci.load_data(subjects=subject, runs=runs)\n",
    "raw = concatenate_raws([read_raw_edf(f, preload=True) for f in fnames])\n",
    "raw.rename_channels(lambda x: x.strip(\".\"))  # remove dots from channel names\n",
    "events, _ = mne.events_from_annotations(raw, event_id=dict(T1=2, T2=3))\n",
    "channel_names = raw.info['ch_names']\n",
    "\n",
    "# Extract trials between -1s and 4s\n",
    "tmin, tmax = -1, 4\n",
    "event_ids = dict(hands=2, feet=3)  # map event IDs to tasks\n",
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    event_ids,\n",
    "    tmin - 0.5,\n",
    "    tmax + 0.5,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "86733254-7769-47d0-a7cd-004b80ff9ed9",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "- For each condition:\n",
    "    - Compute and plot the connectivity matrices based on the estimation of imaginary coherence, averaged over the mu band and across epochs. *Question: What do these matrices reveal about potential changes in brain connectivity between the tasks performed by the subject?*\n",
    "    - Compute and plot the associated node strength, averaged across epochs. *Question: What do these results suggest about potential changes in node strength between the tasks performed by the subject?*\n",
    "\n",
    "- Below is a plot showing the statistical difference between the MI (Motor Imagery) and Rest conditions, derived from imaginary coherence (left) and node strength (right).\n",
    "*Questions:*\n",
    "    - *What do you observe in these plots?*\n",
    "    - *Are these observations neurophysiologically meaningful? Justify your answer.*\n",
    "![Figure_ImCoh](MI_Rest_ImCoh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22149f58-5225-4608-831c-75a542d43db9",
   "metadata": {
    "tags": []
   },
   "source": "## Part 2 - Features in BCI"
  },
  {
   "cell_type": "markdown",
   "id": "6ee67d67-7f68-4277-a271-bb4b29fef966",
   "metadata": {},
   "source": [
    "Here is an EEG dataset to load:"
   ]
  },
  {
   "cell_type": "code",
   "id": "2762da8a-dca3-4dcf-a5d6-626a414bed16",
   "metadata": {},
   "source": [
    "#Define the parameters\n",
    "subject = 1  # use data from subject 1\n",
    "runs = [6, 10, 14]  # Motor imagery: hands vs feet\n",
    "\n",
    "# Extract raw data\n",
    "fnames = eegbci.load_data(subjects=subject, runs=runs)\n",
    "raw = concatenate_raws([read_raw_edf(f, preload=True) for f in fnames])\n",
    "raw.rename_channels(lambda x: x.strip(\".\"))  # remove dots from channel names\n",
    "events, _ = mne.events_from_annotations(raw, event_id=dict(T1=2, T2=3))\n",
    "\n",
    "# Extract trials between -1s and 4s\n",
    "channelsOfInterest = \"T7\", \"C3\", 'O1' # to get the full list of channels you can type: raw.info['ch_names']\n",
    "tmin, tmax = -1, 4\n",
    "event_ids = dict(hands=2, feet=3)  # map event IDs to tasks\n",
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    event_ids,\n",
    "    tmin - 0.5,\n",
    "    tmax + 0.5,\n",
    "    picks=(channelsOfInterest),\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "\n",
    "# Compare power spectra computed in each condition/channel \n",
    "freqs = np.arange(2, 45)\n",
    "vmin, vmax = -1, 1.5  # set min and max ERDS values in plot\n",
    "baseline = (-1, 0)  # baseline interval (in s)\n",
    "cnorm = TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)  # min, center & max ERDS\n",
    "\n",
    "kwargs = dict(\n",
    "    n_permutations=100, step_down_p=0.05, seed=1, buffer_size=None, out_type=\"mask\"\n",
    ")  # for cluster test\n",
    "\n",
    "# Time-Frequency decomposition\n",
    "tfr = tfr_multitaper(\n",
    "    epochs,\n",
    "    freqs=freqs,\n",
    "    n_cycles=freqs,\n",
    "    use_fft=True,\n",
    "    return_itc=False,\n",
    "    average=False,\n",
    "    decim=2,\n",
    ")\n",
    "tfr.crop(tmin, tmax).apply_baseline(baseline, mode=\"percent\")\n",
    "\n",
    "nb_channels = len(channelsOfInterest)\n",
    "for event in event_ids:\n",
    "    # select desired epochs for visualization\n",
    "    tfr_ev = tfr[event]\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 4, figsize=(12, 4), gridspec_kw={\"width_ratios\": [10, 10, 10, 1]}\n",
    "    )\n",
    "    for ch, ax in enumerate(axes[:-1]):  # for each channel\n",
    "        # positive clusters\n",
    "        _, c1, p1, _ = pcluster_test(tfr_ev.data[:, ch], tail=1, **kwargs)\n",
    "        # negative clusters\n",
    "        _, c2, p2, _ = pcluster_test(tfr_ev.data[:, ch], tail=-1, **kwargs)\n",
    "\n",
    "        # note that we keep clusters with p <= 0.05 from the combined clusters\n",
    "        # of two independent tests; in this example, we do not correct for\n",
    "        # these two comparisons\n",
    "        c = np.stack(c1 + c2, axis=2)  # combined clusters\n",
    "        p = np.concatenate((p1, p2))  # combined p-values\n",
    "        mask = c[..., p <= 0.05].any(axis=-1)\n",
    "\n",
    "        # plot TFR (ERDS map with masking)\n",
    "        tfr_ev.average().plot(\n",
    "            [ch],\n",
    "            cmap=\"RdBu\",\n",
    "            cnorm=cnorm,\n",
    "            axes=ax,\n",
    "            colorbar=False,\n",
    "            show=False,\n",
    "            mask=mask,\n",
    "            mask_style=\"mask\",\n",
    "        )\n",
    "\n",
    "        ax.set_title(epochs.ch_names[ch], fontsize=10)\n",
    "        ax.axvline(0, linewidth=1, color=\"black\", linestyle=\":\")  # event\n",
    "        if ch != 0:\n",
    "            ax.set_ylabel(\"\")\n",
    "            ax.set_yticklabels(\"\")\n",
    "    fig.colorbar(axes[0].images[-1], cax=axes[-1]).ax.set_yscale(\"linear\")\n",
    "    fig.suptitle(f\"ERDS ({event})\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bc159f64-b422-4c76-9ee1-562236006fcf",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "- *Describe the observations you can make from the maps. Are these observations neurophysiologically relevant or meaningful? Justify your answer.*\n",
    "- *To what extent are these observations informative for assessing or predicting BCI performance?*\n",
    "- As the experimenter, based on your observations: *Which electrode(s) and frequency bin(s) would you select for feature extraction? Explain why you believe these choices would be optimal for improving BCI performance or interpretability.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c872d66e-039c-476d-b659-f176f3b3170f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": "## Part 3 - Machine Learning & BCI"
  },
  {
   "cell_type": "markdown",
   "id": "77c76632-92e0-4d9c-8d92-11f9744507c6",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "Here is a publicly available [BCI dataset](http://moabb.neurotechx.com/docs/generated/moabb.datasets.BNCI2014_001.html#moabb.datasets.BNCI2014_001) (cf below to load the data and to get information regarding the experimental information). In the following lines of code we defined two classification pipelines (CSP+LDA: Common Spatial Patterns + LDA, RG+LR:Riemannian Geometry + Logistic Regression), and we plotted their performances from a dataset composed of 2 subjects.\n",
    "\n",
    "## Questions\n",
    "- *What key observations can you draw from the plots presented?*\n",
    "- *Instead of the methods implemented here, propose an alternative framework for feature extraction, selection, and classification.*\n",
    "*Sub-questions:*\n",
    "    - *Why would this framework be advantageous?*\n",
    "    - *How would you assess its performance? Provide at least one evaluation metric beyond classical accuracy to assess (mis-)classification.*\n",
    "- Alternative pipeline\n",
    "    - *Implement your proposed framework below and compare its performance to the existing pipelines (RG+LR and CSP+LDA).*\n",
    "    - *What are your findings? Do you have suggestions to further improve the performance of your framework (e.g., feature engineering, sample selection, or preprocessing)?*\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9199147d-56ce-480e-a0df-47dd7d8dafa6",
   "metadata": {},
   "source": [
    "import warnings\n",
    "\n",
    "from mne.decoding import CSP\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "\n",
    "moabb.set_log_level(\"info\")\n",
    "mne.set_log_level(\"CRITICAL\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "###### PIPELINES TO BE COMPARED (do not modify it!) ######\n",
    "# baseline pipeline to be used to make the comparison, please complete the following line with your framework\n",
    "pipelines = {}\n",
    "pipelines[\"CSP+LDA\"] = make_pipeline(CSP(n_components=8), LDA())\n",
    "pipelines[\"RG+LR\"] = make_pipeline(\n",
    "    Covariances(), TangentSpace(), LogisticRegression(solver=\"lbfgs\")\n",
    ")\n",
    "### Implementation of your framework here: ######\n",
    "#pipelines[\"MyPipeline\"] =\n",
    "\n",
    "\n",
    "###### DATASET TO BE USED (do not modify it!) - downloading it the first time can take some time ######\n",
    "dataset = BNCI2014_001()\n",
    "subj = [1, 2]\n",
    "dataset.subject_list = subj\n",
    "\n",
    "\n",
    "###### DEFINITION OF THE PARADIGM & EVALUATION (do not modify it!) ######\n",
    "paradigm = LeftRightImagery()\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm, datasets=dataset, overwrite=False\n",
    ")\n",
    "results = evaluation.process(pipelines)\n",
    "#print(results.head()) # if you want to look at it...\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "983471db-f9a2-49aa-9f7c-9012b0d0fe28",
   "metadata": {},
   "source": [
    "###### SCRIPT TO PLOT THE RESULTS - to be updated with your own pipeline #########\n",
    "# Plot the global distribution of the performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=[8, 4], sharey=True)\n",
    "\n",
    "sns.stripplot(\n",
    "    data=results,\n",
    "    y=\"score\",\n",
    "    x=\"pipeline\",\n",
    "    ax=axes[0],\n",
    "    jitter=True,\n",
    "    alpha=0.5,\n",
    "    zorder=1,\n",
    "    palette=\"rocket\",\n",
    ")\n",
    "sns.pointplot(data=results, y=\"score\", x=\"pipeline\", ax=axes[0], palette=\"rocket\")\n",
    "\n",
    "axes[0].set_ylabel(\"ROC AUC\")\n",
    "axes[0].set_ylim(0.5, 1)\n",
    "\n",
    "paired = results.pivot_table(\n",
    "    values=\"score\", columns=\"pipeline\", index=[\"subject\", \"session\"]\n",
    ")\n",
    "paired = paired.reset_index()\n",
    "\n",
    "sns.regplot(data=paired, y=\"RG+LR\", x=\"CSP+LDA\", ax=axes[1], fit_reg=False)\n",
    "axes[1].plot([0, 1], [0, 1], ls=\"--\", c=\"k\")\n",
    "axes[1].set_xlim(0.5, 1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the individual distribution of the performance\n",
    "g = sns.catplot(\n",
    "    kind=\"bar\",\n",
    "    x=\"score\",\n",
    "    y=\"subject\",\n",
    "    hue=\"pipeline\",\n",
    "    col=\"dataset\",\n",
    "    height=12,\n",
    "    aspect=0.5,\n",
    "    data=results,\n",
    "    orient=\"h\",\n",
    "    palette=\"rocket\",\n",
    ")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "155fb091-bb44-421d-8e8f-8fe9c6f2991c",
   "metadata": {
    "tags": []
   },
   "source": "## Part 4 - Experimental considerations"
  },
  {
   "cell_type": "markdown",
   "id": "9d8e0058-7ee5-4c95-8fea-25f081e239c2",
   "metadata": {},
   "source": [
    "## Questions\n",
    "You plan to launch a new protocol based on EEG acquisitions:\n",
    "- *What are the two main types of artifacts you may observe? Please indicate one example for each of them.*\n",
    "- *What are the main steps that compose an EEG processing pipeline?*\n",
    "\n",
    "You are conducting a Brain-Computer Interface (BCI) experimental protocol consisting of 5 sessions of right-hand motor imagery vs. rest. After the fourth training session, subject Y still shows a global performance of 60%.\n",
    "Protocol details:\n",
    "\n",
    "- At each session, the subject was instructed to perform right-hand motor imagery when the visual target was \"up\" and to remain at rest when the visual target was \"down.\"\n",
    "\n",
    "- The same features were consistently selected: power spectra in CP3 (10 Hz and 14 Hz) and in C3 (12 Hz and 16 Hz).\n",
    "\n",
    "\n",
    "*Based on these observations, what suggestions would you propose to help subject Y improve their performance in session 5?*\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
